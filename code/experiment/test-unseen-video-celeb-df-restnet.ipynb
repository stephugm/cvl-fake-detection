{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bc50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ========== TESTING ON UNSEEN VIDEOS ==========\n",
    "print('\\n' + '='*80)\n",
    "print('TESTING ON UNSEEN VIDEOS')\n",
    "print('='*80)\n",
    "\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
    "# Path to unseen video test data\n",
    "if IS_KAGGLE:\n",
    "    VIDEO_TEST_PATH = '/kaggle/input/video-test-unseen'\n",
    "    MODEL_TEST_PATH = '/kaggle/working/models'\n",
    "    DEBUG_DIR = '/kaggle/working/debug_images'\n",
    "else:\n",
    "    # Use local project folders (relative to notebook working dir)\n",
    "    VIDEO_TEST_PATH = os.path.abspath('video-test-unseen')\n",
    "    MODEL_TEST_PATH = os.path.abspath('models')\n",
    "    DEBUG_DIR = os.path.abspath('debug_images')\n",
    "\n",
    "# Create debug directory\n",
    "os.makedirs(DEBUG_DIR, exist_ok=True)\n",
    "print(f'Debug preprocessed images will be saved to: {DEBUG_DIR}')\n",
    "\n",
    "if os.path.exists(VIDEO_TEST_PATH):\n",
    "    print(f'Unseen video test path found: {VIDEO_TEST_PATH}')\n",
    "    \n",
    "    # Initialize face detector\n",
    "    face_detector = MTCNN()\n",
    "    \n",
    "    def process_unseen_video(video_path, model, img_size, num_frames=10, save_debug=False, video_idx=0, model_name=''):\n",
    "        \"\"\"\n",
    "        Process video with EXACT same preprocessing as training data.\n",
    "        Matches extract_frames_from_video_to_files from import-image-celeb-df.ipynb\n",
    "        \n",
    "        Args:\n",
    "            video_path: Path to video file\n",
    "            model: Loaded Keras model\n",
    "            img_size: Target image size for model\n",
    "            num_frames: Number of frames to extract\n",
    "            save_debug: Whether to save preprocessed images\n",
    "            video_idx: Index of video for debug naming\n",
    "            model_name: Model name for debug file naming\n",
    "        \n",
    "        Returns:\n",
    "            dict with video_name, predictions per frame, and aggregated result\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        if total_frames == 0:\n",
    "            cap.release()\n",
    "            return None\n",
    "        \n",
    "        frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "        frame_predictions = []\n",
    "        \n",
    "        # CRITICAL: Match training preprocessing exactly\n",
    "        FACE_MARGIN = 15  # Same as training\n",
    "        RESIZE_MAX_WIDTH = 640  # Same as training\n",
    "        MIN_CONFIDENCE = 0.8  # Same as training\n",
    "        \n",
    "        video_name = os.path.basename(video_path)\n",
    "        \n",
    "        for frame_num, frame_idx in enumerate(frame_indices):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, int(frame_idx))\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                continue\n",
    "            \n",
    "            # Step 1: Resize frame if too large\n",
    "            h, w = frame.shape[:2]\n",
    "            if w > RESIZE_MAX_WIDTH:\n",
    "                scale = RESIZE_MAX_WIDTH / float(w)\n",
    "                frame = cv2.resize(frame, (RESIZE_MAX_WIDTH, int(h * scale)), \n",
    "                                 interpolation=cv2.INTER_AREA)\n",
    "                h, w = frame.shape[:2]\n",
    "            \n",
    "            # Convert BGR to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Detect face\n",
    "            try:\n",
    "                # Step 2: MTCNN face detection\n",
    "                detections = face_detector.detect_faces(frame_rgb)\n",
    "                if not detections:\n",
    "                    continue\n",
    "                \n",
    "                # Step 3: Select largest face by area (SAME AS TRAINING)\n",
    "                best_face = None\n",
    "                best_area = -1\n",
    "                \n",
    "                for detection in detections:\n",
    "                    box = detection.get('box', None)\n",
    "                    confidence = detection.get('confidence', 0.0)\n",
    "                    \n",
    "                    if box is None or confidence < MIN_CONFIDENCE:\n",
    "                        continue\n",
    "                    \n",
    "                    # box is [x, y, width, height]\n",
    "                    x, y, width, height = box\n",
    "                    area = width * height\n",
    "                    \n",
    "                    if area > best_area:\n",
    "                        best_area = area\n",
    "                        # Store as (x1, y1, x2, y2, confidence)\n",
    "                        best_face = (float(x), float(y), \n",
    "                                   float(x + width), float(y + height), \n",
    "                                   float(confidence))\n",
    "                \n",
    "                if best_face is None:\n",
    "                    continue\n",
    "                \n",
    "                x1, y1, x2, y2, conf = best_face\n",
    "                \n",
    "                # Step 4: Apply FIXED margin (15 pixels, SAME AS TRAINING)\n",
    "                x1i = int(round(x1))\n",
    "                y1i = int(round(y1))\n",
    "                x2i = int(round(x2))\n",
    "                y2i = int(round(y2))\n",
    "                \n",
    "                x0 = max(0, x1i - FACE_MARGIN)\n",
    "                y0 = max(0, y1i - FACE_MARGIN)\n",
    "                x1c = min(frame_rgb.shape[1], x2i + FACE_MARGIN)\n",
    "                y1c = min(frame_rgb.shape[0], y2i + FACE_MARGIN)\n",
    "                \n",
    "                face = frame_rgb[y0:y1c, x0:x1c]\n",
    "                \n",
    "                if face.size == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Step 5: Resize to target size with INTER_AREA (SAME AS TRAINING)\n",
    "                face_resized = cv2.resize(face, (img_size, img_size), \n",
    "                                         interpolation=cv2.INTER_AREA)\n",
    "                \n",
    "                # Save preprocessed image BEFORE normalization (this is what gets fed to model)\n",
    "                if save_debug and frame_num < 5:  # Save first 5 frames per video\n",
    "                    debug_path = os.path.join(DEBUG_DIR, \n",
    "                                            f'{model_name}_vid{video_idx:02d}_{video_name[:-4]}_frame{frame_num:02d}.jpg')\n",
    "                    face_bgr = cv2.cvtColor(face_resized, cv2.COLOR_RGB2BGR)\n",
    "                    cv2.imwrite(debug_path, face_bgr)\n",
    "                    \n",
    "                    if frame_num == 0:  # Print details for first frame only\n",
    "                        print(f\"    Saved: {os.path.basename(debug_path)}\")\n",
    "                        print(f\"    Shape: {face_resized.shape}, Range: [{face_resized.min()}, {face_resized.max()}]\")\n",
    "                \n",
    "                # Step 6: Normalize to [0,1] (SAME AS TRAINING)\n",
    "                face_normalized = face_resized.astype(np.float32) / 255.0\n",
    "                \n",
    "                # Add batch dimension\n",
    "                face_batch = np.expand_dims(face_normalized, axis=0)\n",
    "                \n",
    "                # Predict\n",
    "                pred_prob = model.predict(face_batch, verbose=0)[0][0]\n",
    "                frame_predictions.append(float(pred_prob))\n",
    "                \n",
    "                # Debug: Print first prediction details\n",
    "                if len(frame_predictions) == 1:\n",
    "                    print(f\"    Normalized range: [{face_normalized.min():.3f}, {face_normalized.max():.3f}]\")\n",
    "                    print(f\"    Prediction: {pred_prob:.6f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Frame {frame_idx} error: {e}\")\n",
    "                continue\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        if not frame_predictions:\n",
    "            return None\n",
    "        \n",
    "        # Aggregate predictions\n",
    "        avg_prob = np.mean(frame_predictions)\n",
    "        video_pred = 1 if avg_prob > 0.5 else 0\n",
    "        \n",
    "        return {\n",
    "            'video_name': os.path.basename(video_path),\n",
    "            'frame_predictions': frame_predictions,\n",
    "            'avg_probability': avg_prob,\n",
    "            'prediction': video_pred,\n",
    "            'prediction_label': 'Fake' if video_pred == 1 else 'Real',\n",
    "            'num_frames_processed': len(frame_predictions)\n",
    "        }\n",
    "    \n",
    "    \n",
    "    # Find all video files\n",
    "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv']\n",
    "    unseen_videos = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(VIDEO_TEST_PATH):\n",
    "        for file in files:\n",
    "            if any(file.lower().endswith(ext) for ext in video_extensions):\n",
    "                unseen_videos.append(os.path.join(root, file))\n",
    "    \n",
    "    print(f'\\nFound {len(unseen_videos)} unseen videos')\n",
    "    \n",
    "    if unseen_videos:\n",
    "        # Load best models\n",
    "        print('\\n--- Loading Best Models ---')\n",
    "        print('Loading ResNet50 final model...')\n",
    "        model_resnet_best = keras.models.load_model(\n",
    "            os.path.join(MODEL_TEST_PATH, 'ResNet50_final.keras')\n",
    "        )\n",
    "\n",
    "        # Process videos\n",
    "        print('\\n--- Processing Unseen Videos ---')\n",
    "        unseen_results = []\n",
    "        \n",
    "        for idx, video_path in enumerate(unseen_videos[:10]):  # Process first 10 videos\n",
    "            print(f'\\n[{idx+1}/10] {os.path.basename(video_path)}')\n",
    "            \n",
    "            # ResNet50 prediction with debug images (save for all videos)\n",
    "            print('  ResNet50 (224x224):')\n",
    "            result_resnet = process_unseen_video(\n",
    "                video_path, model_resnet_best, \n",
    "                224, num_frames=10,\n",
    "                save_debug=False, video_idx=idx, model_name='resnet50'\n",
    "            )\n",
    "            \n",
    "            if result_resnet:\n",
    "                unseen_results.append({\n",
    "                    'video_name': result_resnet['video_name'],\n",
    "                    'resnet50_prob': result_resnet['avg_probability'],\n",
    "                    'resnet50_pred': result_resnet['prediction_label'],\n",
    "                    'frames_processed': result_resnet['num_frames_processed']\n",
    "                })\n",
    "                \n",
    "                print(f\"  â†’ ResNet50: {result_resnet['prediction_label']} ({result_resnet['avg_probability']:.4f})\")\n",
    "        \n",
    "        # Clean up models\n",
    "        del model_resnet_best\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        # Display results\n",
    "        if unseen_results:\n",
    "            print('\\n' + '='*80)\n",
    "            print('UNSEEN VIDEO PREDICTIONS SUMMARY')\n",
    "            print('='*80)\n",
    "            unseen_df = pd.DataFrame(unseen_results)\n",
    "            unseen_df['ensemble_pred'] = unseen_df['ensemble_prob'].apply(\n",
    "                lambda x: 'Fake' if x > 0.5 else 'Real'\n",
    "            )\n",
    "            display(unseen_df)\n",
    "            \n",
    "            # Save results\n",
    "            unseen_results_path = os.path.join(PLOTS_DIR, 'unseen_video_predictions.csv')\n",
    "            unseen_df.to_csv(unseen_results_path, index=False)\n",
    "            print(f'\\nPredictions saved to: {unseen_results_path}')\n",
    "            \n",
    "            # Plot predictions\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            x = np.arange(len(unseen_df))\n",
    "            width = 0.25\n",
    "            \n",
    "            ax.bar(x - width, unseen_df['resnet50_prob'], width, label='ResNet50', alpha=0.8)\n",
    "            \n",
    "            ax.axhline(y=0.5, color='r', linestyle='--', label='Decision Threshold')\n",
    "            ax.set_xlabel('Video')\n",
    "            ax.set_ylabel('Fake Probability')\n",
    "            ax.set_title('Unseen Video Predictions')\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels([v[:20] + '...' if len(v) > 20 else v for v in unseen_df['video_name']], \n",
    "                              rotation=45, ha='right')\n",
    "            ax.legend()\n",
    "            ax.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plot_path = os.path.join(PLOTS_DIR, 'unseen_video_predictions.png')\n",
    "            plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "            print(f'Predictions plot saved to: {plot_path}')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print('No videos were successfully processed.')\n",
    "    else:\n",
    "        print('No video files found in the unseen test directory.')\n",
    "else:\n",
    "    print(f'Unseen video test path not found: {VIDEO_TEST_PATH}')\n",
    "    print('Skipping unseen video testing.')\n",
    "\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('DEBUGGING COMPLETE!')\n",
    "print('='*80)\n",
    "print(f'âœ… Preprocessed images saved to: {DEBUG_DIR}')\n",
    "print(f'\\nðŸ“‚ Debug files created:')\n",
    "print(f'   - resnet50_vid##_<videoname>_frame##.jpg   (224x224 preprocessed faces)')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
