{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51afcc58-9c98-4b62-83a8-2dcba7d5bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dlib opencv-python imutils tqdm pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c95e81b-be74-4ae9-bf9a-9de0e1135abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Count: 1\n",
      "GPU Name: NVIDIA GeForce RTX 3070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c567dbf1-2bbb-4f92-8c0d-1f0451bb705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.3.1+cu121\n",
      "CUDA Available: True\n",
      "Device: NVIDIA GeForce RTX 3070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707ae923-76e4-4768-927e-683f85d3f915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡ Testing FaceAnalysis init…\n",
      "❌ Error: This ORT build has ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'] enabled. Since ORT 1.9, you are required to explicitly set the providers parameter when instantiating InferenceSession. For example, onnxruntime.InferenceSession(..., providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'], ...)\n"
     ]
    }
   ],
   "source": [
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "try:\n",
    "    print(\"➡ Testing FaceAnalysis init…\")\n",
    "    app = FaceAnalysis(allowed_modules=['detection'])\n",
    "    app.prepare(ctx_id=0)\n",
    "    print(\"✔ Face detector OK\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48532862-9086-4422-8a8a-6f46878ce5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video exists? True\n",
      "Frames: 303\n"
     ]
    }
   ],
   "source": [
    "import cv2, pandas as pd, os\n",
    "\n",
    "csv = r\"E:\\CVL\\finalproject\\Model Testing\\Datasets\\NeuralTextures.csv\"\n",
    "videos_root = r\"E:\\CVL\\finalproject\\Model Testing\\Datasets\"\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "row = df.iloc[0]\n",
    "path = os.path.join(videos_root, str(row[\"File Path\"]))\n",
    "\n",
    "print(\"Video exists?\", os.path.exists(path))\n",
    "cap = cv2.VideoCapture(path)\n",
    "print(\"Frames:\", int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f58bdca3-281f-4e43-b010-72b5b4f5572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test_video = os.path.join(videos_root, \"Deepfakes\", \"01_02__meeting_serious__YVGY8LOK.mp4\")\n",
    "#print(os.path.exists(test_video), test_video)\n",
    "# -------- CONFIG --------\n",
    "csv_path = r\"E:\\CVL\\finalproject\\Model Testing\\Datasets\\NeuralTextures.csv\"\n",
    "videos_root = r\"E:\\CVL\\finalproject\\Model Testing\\Datasets\"\n",
    "out_root = \"Datasets\"\n",
    "\n",
    "output_size = 256\n",
    "absolute_num = 20\n",
    "train_split = 0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f348c4-28e4-4d4a-be6f-4cb442551063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#test_video = os.path.join(videos_root, \"DeepFakeDetection\", \"01_02__meeting_serious__YVGY8LOK.mp4\")\n",
    "#print(os.path.exists(test_video), test_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9471d5c1-a5f9-4075-bd14-2333919b2176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '1', 'cudnn_conv1d_pad_to_nc1d': '0', 'tunable_op_enabled': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Ariq Sudibyo/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '1', 'cudnn_conv1d_pad_to_nc1d': '0', 'tunable_op_enabled': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Ariq Sudibyo/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '1', 'cudnn_conv1d_pad_to_nc1d': '0', 'tunable_op_enabled': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Ariq Sudibyo/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '1', 'cudnn_conv1d_pad_to_nc1d': '0', 'tunable_op_enabled': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Ariq Sudibyo/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '1', 'cudnn_conv1d_pad_to_nc1d': '0', 'tunable_op_enabled': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Ariq Sudibyo/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "InsightFace working correctly!\n"
     ]
    }
   ],
   "source": [
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "app = FaceAnalysis(name='buffalo_l',\n",
    "                   providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0)  # GPU enabled\n",
    "\n",
    "print(\"InsightFace working correctly!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e245863d-3e31-49e7-8ce2-0fe179ede9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d74c8cf-f50f-4aa3-abd3-fdaf46508dfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '1', 'cudnn_conv1d_pad_to_nc1d': '0', 'tunable_op_enabled': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Ariq Sudibyo/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '1', 'cudnn_conv1d_pad_to_nc1d': '0', 'tunable_op_enabled': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Ariq Sudibyo/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '1', 'cudnn_conv1d_pad_to_nc1d': '0', 'tunable_op_enabled': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Ariq Sudibyo/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '1', 'cudnn_conv1d_pad_to_nc1d': '0', 'tunable_op_enabled': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Ariq Sudibyo/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '1', 'cudnn_conv1d_pad_to_nc1d': '0', 'tunable_op_enabled': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Ariq Sudibyo/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "FaceAnalysis initialized!\n",
      "Starting extraction for 1000 videos...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Conda\\envs\\fakedetection\\lib\\site-packages\\insightface\\utils\\transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [22:40<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extraction Finished!\n",
      "\n",
      "Sample results:\n",
      "(True, 'E:\\\\CVL\\\\finalproject\\\\Model Testing\\\\Datasets\\\\NeuralTextures/000_003.mp4: saved 10 faces')\n",
      "(True, 'E:\\\\CVL\\\\finalproject\\\\Model Testing\\\\Datasets\\\\NeuralTextures/001_870.mp4: saved 10 faces')\n",
      "(True, 'E:\\\\CVL\\\\finalproject\\\\Model Testing\\\\Datasets\\\\NeuralTextures/002_006.mp4: saved 10 faces')\n",
      "(True, 'E:\\\\CVL\\\\finalproject\\\\Model Testing\\\\Datasets\\\\NeuralTextures/003_000.mp4: saved 10 faces')\n",
      "(True, 'E:\\\\CVL\\\\finalproject\\\\Model Testing\\\\Datasets\\\\NeuralTextures/004_982.mp4: saved 10 faces')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# Initialize face detector\n",
    "app = FaceAnalysis(name='buffalo_l', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0)\n",
    "\n",
    "print(\"FaceAnalysis initialized!\")\n",
    "\n",
    "def ensure_dirs():\n",
    "    for sp in [\"train\", \"valid\"]:\n",
    "        for lbl in [\"real\", \"fake\"]:\n",
    "            os.makedirs(os.path.join(out_root, sp, lbl), exist_ok=True)\n",
    "\n",
    "ensure_dirs()\n",
    "\n",
    "def extract_faces(row):\n",
    "    video_rel = row[\"File Path\"]\n",
    "    label = str(row[\"Label\"]).lower()\n",
    "    label_folder = \"real\" if label in [\"real\", \"0\"] else \"fake\"\n",
    "\n",
    "    video_path = os.path.join(videos_root, video_rel)\n",
    "    if not os.path.exists(video_path):\n",
    "        return False, f\"Missing video: {video_path}\"\n",
    "\n",
    "    split = \"train\" if hash(video_path) % 100 < train_split * 100 else \"valid\"\n",
    "    out_dir = os.path.join(out_root, split, label_folder)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames <= 0:\n",
    "        return False, \"No frames\"\n",
    "\n",
    "    # ----- NEW: fixed 10 evenly spaced frames -----\n",
    "    num_frames = 10\n",
    "    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "    frame_indices = sorted(set(frame_indices))\n",
    "    # ----------------------------------------------\n",
    "\n",
    "    saved = 0\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        faces = app.get(frame)\n",
    "        if len(faces) == 0:\n",
    "            continue\n",
    "\n",
    "        # largest face\n",
    "        face = max(faces, key=lambda x: (x.bbox[2] - x.bbox[0]) * (x.bbox[3] - x.bbox[1]))\n",
    "        x1, y1, x2, y2 = map(int, face.bbox)\n",
    "\n",
    "        crop = frame[y1:y2, x1:x2]\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "\n",
    "        crop = cv2.resize(crop, (output_size, output_size))\n",
    "\n",
    "        fname = f\"{os.path.splitext(os.path.basename(video_path))[0]}_{idx:06d}.png\"\n",
    "        cv2.imwrite(os.path.join(out_dir, fname), crop)\n",
    "        saved += 1\n",
    "\n",
    "    cap.release()\n",
    "    return True, f\"{video_path}: saved {saved} faces\"\n",
    "\n",
    "\n",
    "def run():\n",
    "    df = pd.read_csv(csv_path)\n",
    "    res = []\n",
    "\n",
    "    print(f\"Starting extraction for {len(df)} videos...\\n\")\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        ok, msg = extract_faces(row)\n",
    "        res.append((ok, msg))\n",
    "\n",
    "    print(\"\\nExtraction Finished!\")\n",
    "    print(\"\\nSample results:\")\n",
    "    for r in res[:5]:\n",
    "        print(r)\n",
    "\n",
    "\n",
    "run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e40279-e907-4910-8ed9-ef7da9898a51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fakedetection)",
   "language": "python",
   "name": "fakedetection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
